<h1 id="module-tfdata">Module tf.data</h1>
<p>This module contains different class used to manipulate data. Different files format are supported. It also introduces special classes fitted to TensorFlow for encoding/decoding data.</p>
<pre><code class="language-python"># Load the training data into two NumPy arrays, for example using `np.load().
with np.load(&quot;/var/data/training_data.npy&quot;) as data:
  features = data[&quot;features&quot;]
  labels = data[&quot;labels&quot;]

# Assume that each row of `features` corresponds to the same row as `labels.
assert features.shape[0] == labels.shape[0]

dataset = tf.data.Dataset.from_tensor_slices((features, labels))</code></pre>
<p>If you choose tfrecord format for encoding your data, you can use the following way to read (parse) your file(s):</p>
<pre><code class="language-python"># It accepts one or more filenames.
filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
#Apply a transformation function to your data
dataset = dataset.map(func)</code></pre>
<p>If your data is contained in text files, you can use the following way to read (parse) it:</p>
<pre><code class="language-python"># It accepts one or more filenames.
filenames = [&quot;/var/data/file1.txt&quot;, &quot;/var/data/file2.txt&quot;]
dataset = tf.data.TextLineDataset(filenames)</code></pre>
<p>In order to iterate over the dataset, TensorFlow provides the Iterator class:</p>
<pre><code class="language-python"># The returned iterator will be in an uninitialized state, and you must run the iterator.initializer operation before using it:
iterator = dataset.make_initializable_iterator()
tf.Session().run(iterator.initializer)
#Or use one_shot iterator that will be automatically initialized:
iterator = dataset.make_one_shot_iterator()</code></pre>
